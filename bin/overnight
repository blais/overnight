#!/usr/bin/env python3
"""Earnings trading identification tool.

This tool produces a list of tradeable names with earnings AMC or BMO the next
day. Each term is inspected for desirable characteristics.
"""
__copyright__ = "Copyright (C) 2021  Martin Blais"

from decimal import Decimal
from os import path
from typing import Any, Dict, Iterator, List, Optional, Tuple, Union, NamedTuple
import argparse
import collections
import copy
import csv
import datetime
import io
import logging
import math
import os
import re
import time
import urllib.parse

from dateutil import parser
from more_itertools import first
import ameritrade
import click
import jinja2

from johnny.base.etl import petl, Table, Record
from overnight import earnings_pb2 as pb


Json = Union[Dict[str, 'Json'], List['Json'], str, int, float]
ZERO = Decimal('0')
Q = Decimal('0.01')
Qd = Decimal('0.1')
Q1 = Decimal('1.')


# Data for each strike in a chain.
StrikeData = dict[str, Any]

class Expi(NamedTuple):
    """Data for one expiration."""
    info: dict[str, Any]
    puts: list[StrikeData]
    calls: list[StrikeData]

class Chain(NamedTuple):
    """Normalized data for an options chain."""
    info: dict[str, Any]
    expis: dict[datetime.date, Expi]


def get_front_expiration(chain_json: Json):
    """Return the front expiration from the chain."""
    strike_map = first(chain_json['callExpDateMap'].values())
    return [data[0] for data in strike_map.values()]


def normalize_chain(chain_json: Json) -> Chain:
    """Normalize a TD chain response to a simple structure, joining puts and calls
    by expiration."""
    assert chain_json['callExpDateMap'].keys() == chain_json['putExpDateMap'].keys()
    expis = {}
    for expi_str in chain_json['callExpDateMap']:
        expiration = parser.parse(expi_str.split(':')[0]).date()

        puts_json = chain_json['putExpDateMap'][expi_str]
        calls_json = chain_json['callExpDateMap'][expi_str]
        puts = sorted([datalist[0] for datalist in puts_json.values()],
                      key=lambda r: r['strikePrice'], reverse=True)
        calls = sorted([datalist[0] for datalist in calls_json.values()],
                       key=lambda r: r['strikePrice'])

        any_option = first(calls_json.values())[0]
        info = {attr: any_option[attr]
                for attr in ['daysToExpiration', 'expirationDate', 'expirationType']}
        info['expiration'] = expiration

        expis[expiration] = Expi(info, puts, calls)

    chain_info = chain_json.copy()
    del chain_info['callExpDateMap']
    del chain_info['putExpDateMap']
    return Chain(chain_info, expis)


def filter_chain(strikes: list[StrikeData]) -> Table:
    """Filter the options chains for relevant deltas and produce a table."""
    return (petl.fromdicts(strikes)
            .cut('symbol', 'strikePrice', 'bid', 'ask', 'mark', 'last',
                 'theoreticalOptionValue',
                 'askSize', 'bidSize', 'lastSize', 'openInterest', 'totalVolume',
                 'volatility', 'delta', 'gamma', 'theta', 'vega', 'rho', 'description'))


def is_regular_expiration(expi: Expi) -> bool:
    return expi.info['expirationType'] == 'R'


def get_closest_strike(strikes: list[StrikeData],
                       target_price: Decimal) -> tuple[Decimal, int]:
    """Return the closest strike and index from the list."""
    _, strikePrice, index = min([
        (abs(strike.strikePrice - target_price), strike.strikePrice, index)
        for index, strike in enumerate(strikes)])
    return strikePrice.quantize(Q), index


def index_with_default(alist: list[Any], index: int, default: Any) -> Any:
    """Index into a list with a default value."""
    try:
        return alist[index]
    except IndexError:
        return default


def expected_move(chain_info, expi: Expi) -> Optional[tuple[Decimal, Decimal]]:
    """Compute estimates of the expected move."""

    underlyingPrice = chain_info['underlying']['mark']

    try:
        putStrikePrice, index = get_closest_strike(expi.puts, underlyingPrice)
        put0 = expi.puts[index]
        put1 = index_with_default(expi.puts, index + 1, None)
        put2 = index_with_default(expi.puts, index + 2, None)

        callStrikePrice, index = get_closest_strike(expi.calls, underlyingPrice)
        call0 = expi.calls[index]
        call1 = index_with_default(expi.calls, index + 1, None)
        call2 = index_with_default(expi.calls, index + 2, None)
    except IndexError:
        return

    # Q: Is averaging the square better?
    if call0['volatility'] == 'NaN' or put0['volatility'] == 'NaN':
        return
    atm_volatility = (call0['volatility'] + put0['volatility'])/2 / 100

    em_implied = Decimal(float(atm_volatility) *
                         math.sqrt(expi.info['daysToExpiration'] / 365) *
                         float(underlyingPrice)).quantize(Q)

    # Estimate using 60% of 1 strike strangle + 30% of 2 strike strangle + 10%
    # of 3 strike strangle.
    em_straddles = (Decimal('0.60') * (put0.mark + call0.mark) +
                    Decimal('0.30') * (put1.mark if put1 else ZERO +
                                       call1.mark if call1 else ZERO) +
                    Decimal('0.10') * (put2.mark if put2 else ZERO +
                                       call2.mark if call2 else ZERO)).quantize(Q)

    return em_straddles, em_implied, atm_volatility


def get_company_description(chain: Chain) -> str:
    """Return a clean company name."""
    return chain.info['underlying']['description']


TERM_HEADER = [
    'days', 'expdate', 'regular', 'strangle',
    'em', 'em_iv', 'em_avg', 'atm_iv',
    'psprpct', 'pspread', 'pmark',
    'pdelta', 'ptarget', 'pstrike',
    'price',
    'cstrike', 'ctarget', 'cdelta',
    'cmark', 'cspread', 'csprpct',
]
Term = collections.namedtuple('Term', TERM_HEADER)


def safe_quantize(value: Decimal, quantum: Decimal) -> Decimal:
    if value == 'NaN':
        return ZERO
    return value.quantize(quantum)


def get_term(chain: Chain, expi: Expi, config: pb.Config) -> pb.Expiration:
    """Get data for one expiration."""

    # Error messages returned.
    x = pb.Expiration()

    x.is_regular = is_regular_expiration(expi)
    x.days = expi.info['daysToExpiration']
    expiration = expi.info['expiration']
    x.date.year = expiration.year
    x.date.month = expiration.month
    x.date.day = expiration.day

    em_data = expected_move(chain.info, expi)
    if em_data is None:
        x.diagnostics.append("ERROR: Could not calculate EM")
        return x
    em_straddle, em_implied, x.atm_iv = em_data
    em_effective = (em_straddle + em_implied * Decimal('0.85')) / 2
    underlying_price = chain.info['underlying']['mark']
    x.em_straddle = em_straddle
    x.em_implied = em_implied
    x.em_effective = em_effective

    width = Decimal(config.strangle_em_width) * em_effective
    x.put.target = put_target_strike = (underlying_price - width).quantize(Q)
    x.call.target = call_target_strike = (underlying_price + width).quantize(Q)

    x.put.strike, index = get_closest_strike(expi.puts, put_target_strike)
    put_strike = expi.puts[index]
    if put_strike['bidSize'] < config.min_size or put_strike['askSize'] < config.min_size:
        x.diagnostics.append(
            f"WARNING: No size on puts ({put_strike['bidSize']} x {put_strike['askSize']})")
    x.call.strike, index = get_closest_strike(expi.calls, call_target_strike)
    call_strike = expi.calls[index]
    if call_strike['bidSize'] < config.min_size or call_strike['askSize'] < config.min_size:
        x.diagnostics.append(f"WARNING: No size on calls "
                             f"({call_strike['bidSize']} x {call_strike['askSize']})")

    x.put.mark = put_strike['mark']
    x.call.mark = call_strike['mark']

    x.put.spread = put_strike['ask'] - put_strike['bid']
    x.call.spread = call_strike['ask'] - call_strike['bid']
    x.put.spread_frac = x.put.spread / x.put.mark if x.put.mark else 0
    x.call.spread_frac = x.call.spread / x.call.mark if x.call.mark else 0

    if put_strike['delta'] == 'NaN' or call_strike['delta'] == 'NaN':
        x.diagnostics.append("ERROR: Delta is NaN")

    x.put.delta = safe_quantize(put_strike['delta'], Q)
    x.call.delta = safe_quantize(call_strike['delta'], Q)
    if abs(x.put.delta) > config.max_delta or abs(x.call.delta) > config.max_delta:
        x.diagnostics.append(f"WARNING: Delta is too large (>{config.max_delta})")

    x.strangle_cr = x.put.mark + x.call.mark

    # Check for enough credits.
    if x.strangle_cr < config.min_strangle_credits:
        x.diagnostics.append(
            f"WARNING: Not enough credits received (<{config.min_strangle_credits})")

    # Check relative spread size.
    if x.put.spread_frac > config.max_spread_frac:
        x.diagnostics.append(
            f"WARNING: Put spreads are wide (>{config.max_spread_frac:.0%})")
    if x.call.spread_frac > config.max_spread_frac:
        x.diagnostics.append(
            f"WARNING: Call spreads are wide (>{config.max_spread_frac:.0%})")

    return x


def find_regular_expis(chain: Chain) -> Iterator[Expi]:
    """Return the first regular expiration."""
    for date, expi in sorted(chain.expis.items()):
        if is_regular_expiration(expi):
            yield expi


def analyze_earnings(chain_json: Json,
                     config: pb.Config) -> pb.Earnings:
    """Run the analysis on a single earnings name."""

    earnings = pb.Earnings()

    chain = normalize_chain(chain_json)
    earnings.underlying = chain.info['symbol']
    earnings.name = get_company_description(chain)

    underlying = chain.info['underlying']
    earnings.price = underlying['mark']
    earnings.year_high = underlying['fiftyTwoWeekHigh']
    earnings.year_low = underlying['fiftyTwoWeekLow']
    earnings.percent_change = underlying['percentChange']
    earnings.volume = underlying['totalVolume']
    earnings.quote_time = underlying['quoteTime']

    # Get data for the front term if non-regular.
    expi_list = []
    first_expi = first(sorted(chain.expis.items()))[1]
    if not is_regular_expiration(first_expi):
        expi_list.append(first_expi)

    # Get data for all regular expirations up to a maximum.
    for expi in find_regular_expis(chain):
        if expi.info['daysToExpiration'] > config.max_dte:
            break
        expi_list.append(expi)

    # Process each fo the expirations.
    for expi in expi_list:
        if expi is not None:
            earnings.expirations.append(get_term(chain, expi, config))

    # Check volume.
    if earnings.volume < config.volume_threshold:
        earnings.diagnostics.append(
            f"WARNING: Low volume (less than {config.volume_threshold})")

    return earnings


def is_tradeable(earnings: pb.Earnings):
    """Return true if this earnings name has some tradeable expirations."""
    return (not earnings.diagnostics and
            any(not expi.diagnostics for expi in earnings.expirations))


def clean_name(name: str) -> str:
    """Return a cleaned up version of the name, removing common suffixes."""
    return (re.sub(r"(Common Stock|Registered Shares|Inc\.?|S\.A\.|Class [ABC12].*)",
                   "", name)
            .strip(' -,'))

def get_url(name: str) -> str:
    """Return a URL for searching for what the company does.."""
    return "https://www.google.com/search?q={}".format(urllib.parse.quote(clean_name(name)))


def render_earnings_to_html(earlist: pb.EarningsList, outfile: io.IOBase):
    """Render a single HTML file with all the earnings."""

    env = jinja2.Environment(
        loader=jinja2.PackageLoader("overnight", ""),
        autoescape=jinja2.select_autoescape())
    env.globals['get_url'] = get_url
    env.globals['clean_name'] = clean_name

    index = env.get_template("index.html")
    outfile.write(index.render(earlist=earlist,
                               date=datetime.date.today()))


def render_files(symbols: List[str], config: pb.Config, earlist_all: pb.EarningsList,
                 output_dir: str):
    """Render all the output files to a directory."""

    # Create root dir.
    os.makedirs(output_dir, exist_ok=True)

    # Save the input config.
    with open(path.join(output_dir, "config.pbtxt"), "w") as outfile:
        print(config, file=outfile)

    # Write out the evaluated data.
    with open(path.join(output_dir, "earnings.pbtxt"), "w") as outfile:
        print(earlist_all, file=outfile)

    # Copy the input symbols.
    with open(path.join(output_dir, "symbols.csv"), "w") as outfile:
        wr = csv.writer(outfile)
        wr.writerows([(symbol,) for symbol in symbols])

    # Render to a single HTML page.
    with open(path.join(output_dir, "earnings-all.html"), "w") as outfile:
        render_earnings_to_html(earlist_all, outfile)

    # Filter down the list to tradeable ones only and render to another page.
    earlist = pb.EarningsList()
    for earnings in earlist_all.earnings:
        if is_tradeable(earnings):
            earlist.earnings.append(earnings)
    with open(path.join(output_dir, "earnings.html"), "w") as outfile:
        render_earnings_to_html(earlist, outfile)


def main():
    parser = argparse.ArgumentParser()
    ameritrade.add_args(parser)
    parser.add_argument('symbols', nargs='*',
                        help='Symbols to process')
    parser.add_argument('--csv-filename', '-f', action='store',
                        help='CSV filename to read symbols from')
    parser.add_argument('-v', '--verbose', action='store_true')
    parser.add_argument('-r', '--rate-limit', action='store_true',
                        help="Turn on rate limitations for large lists")
    parser.add_argument('--output', action='store',
                        help='Output directory to write results to.')
    args = parser.parse_args()
    config = ameritrade.config_from_args(args)
    td = ameritrade.open(config)

    if args.verbose:
        logging.basicConfig(level=logging.INFO, format='%(levelname)-8s: %(message)s')

    # Fixed configuration.
    # TODO(blais): Allow reading this from a file.
    config = pb.Config()
    config.max_dte = 60
    config.max_delta = 0.20
    config.volume_threshold = 100_000
    config.min_strangle_credits = 0.40
    config.max_spread_frac = 0.50
    config.min_size = 1
    config.strangle_em_width = 2.0

    symbols = []
    if args.csv_filename:
        symbols_table = petl.fromcsv(args.csv_filename)
        symbols.extend(symbols_table.sort('Symbol').values('Symbol'))
    if args.symbols:
        symbols.extend(args.symbols)

    earlist_all = pb.EarningsList()

    header = ['symbol', 'description', 'volume'] + TERM_HEADER + ['url']
    rows = [header]
    max_date = datetime.date.today() + datetime.timedelta(days=config.max_dte + 7)
    for symbol in symbols:
        logging.info(f",--{symbol}---------------------------------------------------------------")

        # Fetch the option chain.
        while True:
            chain_json = td.GetOptionChain(symbol=symbol,
                                           includeQuotes=True,
                                           toDate=max_date)

            # Half-assed recovery from rate limit hit.
            # TODO(blais): Properly handle this in the API code.
            if args.rate_limit:
                time.sleep(0.1)
            if ('error' in chain_json and
                re.search('transactions per seconds restriction reached',
                          chain_json['error'])):
                logging.warning("Rate-limit hit; throttling for 5 secs...")
                time.sleep(5)
                continue
            break

        # Handle errors fetching.
        earnings = earlist_all.earnings.add()
        earnings.underlying = symbol
        if chain_json['status'] == 'FAILED' or 'callExpDateMap' not in chain_json:
            logging.warning(f"Could not get chain data for {symbol}")
            earnings.success = False
            earnings.diagnostics.append(f"ERROR: Could not get chain data for {symbol}")
            continue
        else:
            earnings.success = True
            earnings.CopyFrom(analyze_earnings(chain_json, config))

    # Render output.
    if not args.output:
        print(earlist_all)
    else:
        render_files(symbols, config, earlist_all, args.output)


if __name__ == '__main__':
    main()
